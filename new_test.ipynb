{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.12.1+cu116\n",
      "0.13.1+cu116\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from pandas.core.common import flatten\n",
    "\n",
    "import torch\n",
    "from torchvision import datasets, models, transforms\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import cv2\n",
    "\n",
    "import random\n",
    "import glob as glob\n",
    "\n",
    "print(torch.__version__)\n",
    "print(torchvision.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = \"C:/Users/guzma/OneDrive/Documents/TEC/DTU/02456/Project/Github_Project/autotetris/small_sample_out/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms = A.Compose(\n",
    "    [\n",
    "        A.SmallestMaxSize(max_size=350),\n",
    "        A.ShiftScaleRotate(shift_limit=0.05, scale_limit=0.05, rotate_limit=360, p=0.5),\n",
    "        A.RandomCrop(height=256, width=256),\n",
    "        A.RGBShift(r_shift_limit=15, g_shift_limit=15, b_shift_limit=15, p=0.5),\n",
    "        A.RandomBrightnessContrast(p=0.5),\n",
    "        A.MultiplicativeNoise(multiplier=[0.5,2], per_channel=True, p=0.2),\n",
    "        A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "        A.HueSaturationValue(hue_shift_limit=0.2, sat_shift_limit=0.2, val_shift_limit=0.2, p=0.5),\n",
    "        A.RandomBrightnessContrast(brightness_limit=(-0.1,0.1), contrast_limit=(-0.1, 0.1), p=0.5),\n",
    "        ToTensorV2(),\n",
    "    ]\n",
    ")\n",
    "\n",
    "test_transforms = A.Compose(\n",
    "    [\n",
    "        A.SmallestMaxSize(max_size=350),\n",
    "        A.CenterCrop(height=256, width=256),\n",
    "        A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "        ToTensorV2(),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_image_path example:  C:/Users/guzma/OneDrive/Documents/TEC/DTU/02456/Project/Github_Project/autotetris/small_sample_out\\a59bdbeb-08a8-4425-bde7-2f2253af5545-b15-otovowms.jpeg\n",
      "class example:  012f1988-d8c7-4704-af42-4c063a07054e-b15-otovowms.jpeg\n",
      "Train size: 80\n",
      "Valid size: 21\n"
     ]
    }
   ],
   "source": [
    "train_data_path = input_path\n",
    "# test_data_path = 'images/test'\n",
    "\n",
    "train_image_paths = [] #to store image paths in list\n",
    "classes = [] #to store class values\n",
    "\n",
    "#1.\n",
    "# get all the paths from train_data_path and append image paths and class to to respective lists\n",
    "# eg. train path-> 'images/train/26.Pont_du_Gard/4321ee6695c23c7b.jpg'\n",
    "# eg. class -> 26.Pont_du_Gard\n",
    "for data_path in glob.glob(train_data_path + '*'):\n",
    "    classes.append(data_path.split('\\\\')[-1]) \n",
    "    train_image_paths.append(glob.glob(data_path + '*'))\n",
    "    \n",
    "train_image_paths = list(flatten(train_image_paths))\n",
    "random.shuffle(train_image_paths)\n",
    "\n",
    "print('train_image_path example: ', train_image_paths[0])\n",
    "print('class example: ', classes[0])\n",
    "\n",
    "#2.\n",
    "# split train valid from train paths (80,20)\n",
    "train_image_paths, valid_image_paths = train_image_paths[:int(0.8*len(train_image_paths))], train_image_paths[int(0.8*len(train_image_paths)):] \n",
    "\n",
    "#3.\n",
    "# create the test_image_paths\n",
    "# test_image_paths = []\n",
    "# for data_path in glob.glob(test_data_path + '/*'):\n",
    "#     test_image_paths.append(glob.glob(data_path + '/*'))\n",
    "\n",
    "# test_image_paths = list(flatten(test_image_paths))\n",
    "\n",
    "print(\"Train size: {}\\nValid size: {}\".format(len(train_image_paths), len(valid_image_paths)))# , len(test_image_paths)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_to_class = {i:j for i, j in enumerate(classes)}\n",
    "class_to_idx = {value:key for key,value in idx_to_class.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RoofDataset(Dataset):\n",
    "    def __init__(self, image_paths, transform=False):\n",
    "        self.image_paths = image_paths\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_filepath = self.image_paths[idx]\n",
    "        image = cv2.imread(image_filepath)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        label = image_filepath.split('\\\\')[-1]\n",
    "        label = class_to_idx[label]\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image=image)[\"image\"]\n",
    "        \n",
    "        return image, label\n",
    "    \n",
    "#######################################################\n",
    "#                  Create Dataset\n",
    "#######################################################\n",
    "\n",
    "train_dataset = RoofDataset(train_image_paths,train_transforms)\n",
    "valid_dataset = RoofDataset(valid_image_paths,test_transforms) #test transforms are applied\n",
    "# test_dataset = RoofDataset(test_image_paths,test_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of tensor for 50th image in train dataset:  torch.Size([3, 256, 256])\n",
      "The label for 50th image in train dataset:  15\n"
     ]
    }
   ],
   "source": [
    "print('The shape of tensor for 50th image in train dataset: ',train_dataset[49][0].shape)\n",
    "print('The label for 50th image in train dataset: ',train_dataset[49][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(\n",
    "    train_dataset, batch_size=64, shuffle=True\n",
    ")\n",
    "\n",
    "valid_loader = DataLoader(\n",
    "    valid_dataset, batch_size=64, shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:/Users/guzma/OneDrive/Documents/TEC/DTU/02456/Project/Github_Project/autotetris/small_sample_out'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_path[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "#                                  std=[0.229, 0.224, 0.225])\n",
    "\n",
    "# data_transforms = {\n",
    "#     'train':\n",
    "#     transforms.Compose([\n",
    "#         transforms.Resize((224,224)),\n",
    "#         transforms.RandomAffine(0, shear=10, scale=(0.8,1.2)),\n",
    "#         transforms.RandomHorizontalFlip(),\n",
    "#         transforms.ToTensor(),\n",
    "#         normalize\n",
    "#     ]),\n",
    "#     # 'validation':\n",
    "#     # transforms.Compose([\n",
    "#     #     transforms.Resize((224,224)),\n",
    "#     #     transforms.ToTensor(),\n",
    "#     #     normalize\n",
    "#     # ]),\n",
    "# }\n",
    "\n",
    "# image_datasets = {\n",
    "#     'train': \n",
    "#     datasets.ImageFolder(input_path, data_transforms['train']),\n",
    "#     # 'validation': \n",
    "#     # datasets.ImageFolder(input_path, data_transforms['validation'])\n",
    "# }\n",
    "\n",
    "dataloaders = {\n",
    "    'train':\n",
    "        train_loader, \n",
    "    'validation':\n",
    "        valid_loader\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.resnet50(pretrained=False).to(device)\n",
    "    \n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False   \n",
    "    \n",
    "model.fc = nn.Sequential(\n",
    "               nn.Linear(2048, 128),\n",
    "               nn.ReLU(inplace=True),\n",
    "               nn.Linear(128, 2)).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.fc.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, num_epochs=3):\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch+1, num_epochs))\n",
    "        print('-' * 10)\n",
    "\n",
    "        for phase in ['train', 'validation']:\n",
    "            if phase == 'train':\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                if phase == 'train':\n",
    "                    optimizer.zero_grad()\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            epoch_loss = running_loss / 80\n",
    "            epoch_acc = running_corrects.double() / 21\n",
    "\n",
    "            print('{} loss: {:.4f}, acc: {:.4f}'.format(phase,\n",
    "                                                        epoch_loss,\n",
    "                                                        epoch_acc))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "----------\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\guzma\\OneDrive\\Documents\\TEC\\DTU\\02456\\Project\\Github_Project\\autotetris\\new_test.ipynb Cell 16\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/guzma/OneDrive/Documents/TEC/DTU/02456/Project/Github_Project/autotetris/new_test.ipynb#X11sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m model_trained \u001b[39m=\u001b[39m train_model(model, criterion, optimizer, num_epochs\u001b[39m=\u001b[39;49m\u001b[39m3\u001b[39;49m)\n",
      "\u001b[1;32mc:\\Users\\guzma\\OneDrive\\Documents\\TEC\\DTU\\02456\\Project\\Github_Project\\autotetris\\new_test.ipynb Cell 16\u001b[0m in \u001b[0;36mtrain_model\u001b[1;34m(model, criterion, optimizer, num_epochs)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/guzma/OneDrive/Documents/TEC/DTU/02456/Project/Github_Project/autotetris/new_test.ipynb#X11sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m running_corrects \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/guzma/OneDrive/Documents/TEC/DTU/02456/Project/Github_Project/autotetris/new_test.ipynb#X11sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39mfor\u001b[39;00m inputs, labels \u001b[39min\u001b[39;00m dataloaders[phase]:\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/guzma/OneDrive/Documents/TEC/DTU/02456/Project/Github_Project/autotetris/new_test.ipynb#X11sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m     inputs \u001b[39m=\u001b[39m inputs\u001b[39m.\u001b[39;49mto(device)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/guzma/OneDrive/Documents/TEC/DTU/02456/Project/Github_Project/autotetris/new_test.ipynb#X11sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m     labels \u001b[39m=\u001b[39m labels\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/guzma/OneDrive/Documents/TEC/DTU/02456/Project/Github_Project/autotetris/new_test.ipynb#X11sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m     outputs \u001b[39m=\u001b[39m model(inputs)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1."
     ]
    }
   ],
   "source": [
    "model_trained = train_model(model, criterion, optimizer, num_epochs=3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9959bfa401c4caffb955641b8073b423143544ccdcedf37cb9b7539bcd316359"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
