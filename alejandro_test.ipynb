{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.13.0\n",
      "0.2.2\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from pandas.core.common import flatten\n",
    "\n",
    "import torch\n",
    "import os\n",
    "from torchvision import datasets, models, transforms\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import cv2\n",
    "\n",
    "import random\n",
    "import glob as glob\n",
    "\n",
    "print(torch.__version__)\n",
    "print(torchvision.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = os.path.dirname(\"/Users/alex_christlieb/Desktop/small_sample_out/\")\n",
    "# image_path = \"/Users/alex_christlieb/Desktop/small_sample_out/\"+img_name+\"-b15-otovowms.jpeg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 100\n",
      "Valid size: \n"
     ]
    }
   ],
   "source": [
    "\"\"\"Construct paths for lists\"\"\"\n",
    "image_paths = []\n",
    "# test_data_path = 'images/test'\n",
    "\n",
    "# train_image_paths = [] #to store image paths in list\n",
    "# classes = [] #to store class values\n",
    "\n",
    "#1.\n",
    "# get all the paths from train_data_path and append image paths and class to to respective lists\n",
    "# eg. train path-> 'images/train/26.Pont_du_Gard/4321ee6695c23c7b.jpg'\n",
    "# eg. class -> 26.Pont_du_Gard\n",
    "for data_path in glob.glob(input_path + '*'):\n",
    "    #-------------- Mac -------------\n",
    "    # classes.append(data_path.split('/')[-1]) \n",
    "    image_paths.append(glob.glob(data_path + '/*.jpeg')) \n",
    "\n",
    "    #-------------- Windows -------------\n",
    "    # classes.append(data_path.split('\\\\')[-1])  \n",
    "    # image_paths.append(glob.glob(data_path + '*')) \n",
    "\n",
    "    \n",
    "train_image_paths = list(flatten(image_paths))\n",
    "\n",
    "# print('train_image_path example: ', train_image_paths[0])\n",
    "# print('class example: ', classes[0])\n",
    "\n",
    "#2.\n",
    "# split train valid from train paths (80,20)\n",
    "# train_image_paths, valid_image_paths = train_image_paths[:int(0.8*len(train_image_paths))], train_image_paths[int(0.8*len(train_image_paths)):] \n",
    "\n",
    "#3.\n",
    "# create the test_image_paths\n",
    "# test_image_paths = []\n",
    "# for data_path in glob.glob(test_data_path + '/*'):\n",
    "#     test_image_paths.append(glob.glob(data_path + '/*'))\n",
    "\n",
    "# test_image_paths = list(flatten(test_image_paths))\n",
    "\n",
    "# print(\"Train size: {}\\nValid size: \".format(len(train_image_paths)))# , len(test_image_paths)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RoofDataset(Dataset):\n",
    "    def __init__(self, image_paths, transform=False):\n",
    "        self.image_paths = image_paths\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_filepath = self.image_paths[idx]\n",
    "        image = cv2.imread(image_filepath)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        label = image_filepath.split('\\\\')[-1]\n",
    "        label = class_to_idx[label]\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image=image)[\"image\"]\n",
    "        \n",
    "        return image, label\n",
    "    \n",
    "#######################################################\n",
    "#                  Create Dataset\n",
    "#######################################################\n",
    "\n",
    "full_dataset = RoofDataset(train_image_paths)\n",
    "# valid_dataset = RoofDataset(valid_image_paths,test_transforms) #test transforms are applied\n",
    "# test_dataset = RoofDataset(test_image_paths,test_transforms)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d7984c3a34ea110ad9390dcd7f381a8abffaaffaf437aab2d74e29e80f38c444"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
